{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f3135a5-daeb-42dd-85f0-4766d070b3fb",
   "metadata": {},
   "source": [
    "### Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf332e76-3e11-40b6-ac83-b35ffabbfa5f",
   "metadata": {},
   "source": [
    "**Bayes' theorem, named after the Reverend Thomas Bayes, is a fundamental concept in probability theory and statistics. It provides a way to update or revise probabilities based on new evidence or information. The theorem is expressed mathematically as:**\n",
    "\n",
    "**P(A∣B)= P(B∣A)⋅P(A)/P(B)**\n",
    "\n",
    "##### Where:\n",
    "- P(A∣B) is the probability of event A occurring given that event B has occurred (posterior probability).\n",
    "- P(B∣A) is the probability of event B occurring given that event A has occurred (likelihood).\n",
    "- P(A) is the prior probability of event A.\n",
    "- P(B) is the prior probability of event B.\n",
    "\n",
    "**In words, Bayes' theorem helps us update our belief in the probability of an event A based on the occurrence of another event B and the prior probabilities of A and B.**\n",
    "\n",
    "##### This theorem is widely used in various fields, including statistics, machine learning, and artificial intelligence, particularly in the context of Bayesian inference. It plays a crucial role in updating probabilities and making predictions as new evidence becomes available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62116bff-8db7-41b8-b50b-b3d231c443d3",
   "metadata": {},
   "source": [
    "### Q2. What is the formula for Bayes' theorem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e88c0-0e9f-4019-8a18-0b79acd69c6b",
   "metadata": {},
   "source": [
    "\n",
    "**P(A∣B)= P(B∣A)⋅P(A)/P(B)**\n",
    "\n",
    "##### Where:\n",
    "- P(A∣B) is the probability of event A occurring given that event B has occurred (posterior probability).\n",
    "- P(B∣A) is the probability of event B occurring given that event A has occurred (likelihood).\n",
    "- P(A) is the prior probability of event A.\n",
    "- P(B) is the prior probability of event B.\n",
    "\n",
    "**In words, Bayes' theorem helps us update our belief in the probability of an event A based on the occurrence of another event B and the prior probabilities of A and B.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4475df-ca4e-4b48-9d38-252ea7b0c79a",
   "metadata": {},
   "source": [
    "### Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1986b04a-c694-433d-b2ef-7a76fbfac8d6",
   "metadata": {},
   "source": [
    "**Bayes' theorem is used in practice in various fields to update probabilities based on new evidence. Here are a few examples of how Bayes' theorem is applied in different areas:**\n",
    "\n",
    "##### 1. Medical Diagnosis:\n",
    "\n",
    "- Given a certain medical test result (evidence), Bayes' theorem can be used to update the probability of a patient having a particular disease.\n",
    "\n",
    "- **P(Disease|Test Result)= P(Test Result|Disease)⋅P(Disease)/P(Test Result)**\n",
    "\n",
    "\n",
    "\n",
    "- It helps in refining the probability of a disease after considering the test results and the prevalence of the disease.\n",
    "\n",
    "##### 2. Spam Filtering:\n",
    "\n",
    "- In email spam filtering, Bayes' theorem is used in Bayesian spam filters to classify emails as spam or not spam based on the occurrence of certain words or features.\n",
    "\n",
    "- **P(Spam|Word)= P(Word|Spam)⋅P(Spam)/P(Word)**\n",
    "\n",
    "- The probability of an email being spam is updated based on the probability of seeing certain words in spam emails and the overall prevalence of spam.\n",
    "\n",
    "##### 3. Machine Learning and Classification:\n",
    "\n",
    "- In machine learning, Bayes' theorem is fundamental to Naive Bayes classifiers.\n",
    "- These classifiers use the theorem to estimate the probability of a particular class given the observed features.\n",
    "- It's particularly useful when the independence assumption holds (Naive Bayes assumes that features are independent given the class).\n",
    "\n",
    "##### 4. Weather Prediction:\n",
    "\n",
    "- Bayesian methods can be applied in weather forecasting to update the probability of certain weather conditions based on new observations and historical data.\n",
    "\n",
    "- **P(Rain|Cloudy)= P(Cloudy|Rain)⋅P(Rain)/P(Cloudy)**\n",
    " \n",
    "- It helps in adjusting the probability of rain given the observation of cloudy conditions.\n",
    "\n",
    "**In these examples and many others, Bayes' theorem provides a framework for updating beliefs or probabilities as new information becomes available, making it a powerful tool for decision-making and inference in uncertain situations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad29d7c-5e3b-4611-a158-ab1320885c9a",
   "metadata": {},
   "source": [
    "**Certainly! In Python, you can implement Bayes' theorem for medical diagnosis, specifically for the case of diabetes. Let's assume you have the following probabilities:**\n",
    "\n",
    "P(Diabetes): Prior probability of having diabetes.\n",
    "\n",
    "- P(Test Positive | Diabetes): Probability of testing positive given that a person has diabetes.\n",
    "\n",
    "\n",
    "- P(Test Negative | No Diabetes): Probability of testing negative given that a person does not have diabetes.\n",
    "\n",
    "**ere's a simple Python function to calculate the updated probability of having diabetes given a test result:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34edd44f-3afd-45c3-8ba2-0a46afb184b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated probability of having diabetes given a positive test result is: 0.21126760563380279\n"
     ]
    }
   ],
   "source": [
    "def bayes_diagnosis(p_diabetes, p_positive_given_diabetes, p_negative_given_no_diabetes):\n",
    "    # Bayes' theorem formula\n",
    "    p_diabetes_given_positive = (p_positive_given_diabetes * p_diabetes) / (\n",
    "        (p_positive_given_diabetes * p_diabetes) + (p_negative_given_no_diabetes * (1 - p_diabetes))\n",
    "    )\n",
    "    return p_diabetes_given_positive\n",
    "\n",
    "# Example probabilities (you can replace these with actual values)\n",
    "p_diabetes = 0.5  # Prior probability of having diabetes\n",
    "p_positive_given_diabetes = 0.15  # Probability of testing positive given diabetes\n",
    "p_negative_given_no_diabetes = 0.56  # Probability of testing negative given no diabetes\n",
    "\n",
    "# Calculate updated probability using the function\n",
    "result = bayes_diagnosis(p_diabetes, p_positive_given_diabetes, p_negative_given_no_diabetes)\n",
    "\n",
    "# Print the result\n",
    "print(f\"The updated probability of having diabetes given a positive test result is: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b14a85-74df-43b8-95c2-63abcec0ceca",
   "metadata": {},
   "source": [
    "### Q4. What is the relationship between Bayes' theorem and conditional probability?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65a8dd2-c077-44d6-911b-311b53e53d15",
   "metadata": {},
   "source": [
    "**Bayes' theorem and conditional probability are closely related concepts. Bayes' theorem is essentially a formula that relates conditional probabilities. To understand their relationship, let's first define conditional probability.**\n",
    "\n",
    "##### Conditional Probability:\n",
    "\n",
    "- Conditional probability is the probability of an event occurring given that another event has already occurred. Mathematically, if we denote the events as A and B, the conditional probability of A given B is denoted as \n",
    "\n",
    "**P(A∣B) and is calculated as:**\n",
    "\n",
    "- **P(A∣B)= P(A∩B)/P(B)**\n",
    "\n",
    "**where**\n",
    "\n",
    "- P(A∩B) is the probability of both events A and B occurring together.\n",
    "\n",
    "**Bayes' Theorem:**\n",
    "\n",
    "- Bayes' theorem is a way of updating probabilities based on new evidence. It relates the conditional probability of event A given B to the conditional probability of B given A. The formula is:\n",
    "\n",
    "- **P(A∣B)= P(B∣A)⋅P(A)/P(B)**\n",
    "\n",
    "- _In this formula:_\n",
    "\n",
    "- P(A∣B) is the conditional probability of A given B (posterior probability).\n",
    "- P(B∣A) is the conditional probability of B given A (likelihood).\n",
    "- P(A) is the prior probability of A.\n",
    "\n",
    "**P(B) is the prior probability of B.**\n",
    "\n",
    "##### Relationship:\n",
    "- The relationship between Bayes' theorem and conditional probability becomes evident when you look at the expression for \n",
    "\n",
    "**P(A∣B) in Bayes' theorem. It essentially expresses the conditional probability of A given B in terms of the prior probability of A, the likelihood of B given A, and the prior probability of B.**\n",
    "\n",
    "###### In summary, Bayes' theorem is a generalized form of expressing conditional probability, providing a systematic way to update probabilities based on new information. Conditional probability is a specific case of this theorem when it focuses on the probability of one event given the occurrence of another. Bayes' theorem is a powerful tool in statistics, machine learning, and various fields where probability and uncertainty are involved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58872907-4880-43d9-8fbe-b91a0b78f723",
   "metadata": {},
   "source": [
    "### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc7041a-7318-43dd-9f30-b0abbbf03518",
   "metadata": {},
   "source": [
    "##### The choice of which type of Naive Bayes classifier to use for a given problem depends on the nature of the data and the assumptions you are willing to make about the independence of features. There are three main types of Naive Bayes classifiers:\n",
    "\n",
    "**1. Gaussian Naive Bayes:**\n",
    "\n",
    "- Assumption: Assumes that the features follow a normal (Gaussian) distribution.\n",
    "- Use Case: Suitable for continuous or real-valued features.\n",
    "\n",
    "**2. Multinomial Naive Bayes:**\n",
    "\n",
    "- Assumption: Assumes that features are multinomially distributed, which is appropriate for discrete data (e.g., word counts in a document).\n",
    "- Use Case: Commonly used in text classification problems, where features represent word frequencies or presence in a document.\n",
    "\n",
    "**3. Bernoulli Naive Bayes:**\n",
    "\n",
    "- Assumption: Assumes that features are binary (presence or absence).\n",
    "- Use Case: Often used for binary or Boolean features, such as word presence/absence in document classification tasks.\n",
    "\n",
    "\n",
    "##### How to Choose:\n",
    "\n",
    "**Nature of Features:**\n",
    "\n",
    "- If your features are continuous, Gaussian Naive Bayes may be suitable.\n",
    "- For binary features, Bernoulli Naive Bayes is often appropriate.\n",
    "- If the features are counts or frequencies of events (especially in text data), Multinomial Naive Bayes might be a good choice.\n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "- Consider the assumptions made by each type and whether they align with the characteristics of your data. For example, if the independence assumption is reasonable for your problem, Naive Bayes classifiers can work well.\n",
    "\n",
    "**Performance in Practice:**\n",
    "\n",
    "- Experiment with different Naive Bayes classifiers on your specific dataset and evaluate their performance using metrics such as accuracy, precision, recall, and F1 score.\n",
    "- Cross-validation or other validation techniques can help you assess how well each type of classifier generalizes to new data.\n",
    "\n",
    "**Data Size:**\n",
    "\n",
    "- Naive Bayes classifiers, in general, are computationally efficient and can work well with small datasets.\n",
    "- If your dataset is small, Naive Bayes classifiers may be a good choice.\n",
    "\n",
    "###### In practice, it's often a good idea to try multiple types of Naive Bayes classifiers and compare their performance on your specific problem. The choice may also depend on the specific requirements and characteristics of your application.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f42037d-94da-4563-b4a4-66257c6c1d04",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Q6. You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "### Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1631811-4939-4a06-a746-8b1978b5b4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "**Class X1=1   X1=2   X1=3   X2=1   X2=2   X2=3   X2=4**\n",
    "    **A    3      3      4      4      3      3      3**\n",
    "    **B    2      2      1      2      2      2      3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7272a3-1e70-4deb-8aec-5ce08644f8f0",
   "metadata": {},
   "source": [
    "In Naive Bayes classification, you calculate the likelihood of each class given the observed feature values and then choose the class with the highest likelihood. The formula for calculating the likelihood is:\n",
    "P(X∣C)∝P(C)×P(X1∣C)×P(X2∣C)\n",
    "\n",
    "**Assuming equal prior probabilities for each class (P(CA)=P(CB)), you can ignore the P(C) term in the comparison, and your decision is based on the product of P(X1∣C) and P(X2∣C).**\n",
    "\n",
    "Let's calculate for Class A:\n",
    "\n",
    "- P(X1=3∣A)= 4/13\n",
    "- P(X2=4∣A)= 3/13\n",
    "\n",
    "**The product is**\n",
    "\n",
    "- 4/13×3/13= 12/169\n",
    "\n",
    "Now, let's calculate for Class B:\n",
    "- P(X1=3∣B)= 1/7\n",
    "- P(X2=4∣B)= 3/7\n",
    "**The product is** \n",
    "- 1/7×3/7= 3/49\n",
    "###### Comparing the products,  12/169>3/49, so Naive Bayes would predict the new instance to belong to Class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f59f4c-49e3-4d48-8f25-65855b9f345c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
